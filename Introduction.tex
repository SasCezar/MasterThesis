\chapter{Introduction}
\paragraph{}

With the advent of the Internet, a large amount of digital text is produced each day as news articles, research publications, blogs, and social media. It is essential to advance techniques for extracting information automatically from these documents, as much valuable knowledge is hidden within them. This extracted information can be used to enhance access and management of knowledge hidden in large text corpora. 

However, most of this information is produced only in English; for example, it is a widely lamented fact that linguistic and encyclopedic resources are heavily biased towards English. Even multilingual knowledge bases (KBs) such as Wikidata \citep{vwikidata} are predominantly English-based \citep{Kaffee:Simperl:18}. This suggests that coverage is higher for English and that facts of interest to English-speaking communities are more likely included in a KB.

This also means that current relation extraction, and in general Natural Language Processing (NLP), research and development has mainly focused on English. Recognizing this, the community has in recent years put emphasis on multilingual and cross-lingual methods which allow for the joint exploitation of resources between languages and for the transfer of models from well-resourced languages to lower-resourced ones.

In this work, we will discuss such problems in the context of Relation Extraction (RE), which is an Information Extraction (IE) subtask. IE is a field that concerns NLP, computational linguistic, and data mining. The goal of IE is to extract structured information from a collection of unstructured documents, this is achieved via different subtask like Named Entity Recognition, coreference resolution, and relation extraction. The task of relation extraction consists of identifying mentions of the relations of interest in each sentence of the given documents, the extracted relation are then used to populate knowledge bases. Traditional relation extraction system are required to only extract seen relations, which make easier to train these models as the data required can be obtained via crowd sourcing~\citep{liu-etal-2016-effective} or distant supervision~\citep{hoffmann-etal-2011-knowledge}. When the relations of interest were not in the training data traditional solutions are not able to extract the relations. To solve this problem,~\cite{levy2017zero} proposes an alternative approach to the relation extraction task, by reframing relation extraction as a question answering problem, they can use reading comprehension techniques that allow zero-shot relation extraction. 
Based on~\citep{levy2017zero, hewlett2016wikireading} we propose X-WikiRE, a new multilingual resource for relation extraction as question answering. Moreover, using state-of-the-art machine comprehension for question answering, we show how our multilingual resource helps both


% This work explores techniques for automatically filling such language gaps by learning to add facts in other languages, and more generally shows that multilingual sharing is beneficial for knowledge base completion. 


\paragraph{}
This work is organized through the following chapters: in Chapter~\ref{chpt:2} we will present some natural language processing and machine learning concepts and methodologies background. In Chapter~\ref{chpt:3} we will present the state of the art in relation extraction and machine comprehension. Next, Chapter~\ref{chpt:4} presents our new multilingual relation extraction dataset; while in Chapter~\ref{chpt:5} we will describe our solution. Finally, in Chapter~\ref{chpt:6} we present some results using our dataset and comparison with a monolingual system. To conclude, Chapter~\ref{chpt:7} contains some final thoughts and future developments.